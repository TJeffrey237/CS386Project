# Description #
Upkeep is a 2D pixel art puzzle game that places players in the role of a house renovator. The core gameplay involves selecting renovation tasks and solving environment-based puzzles to restore homes for a variety of homeowners. With each house comes a unique set of puzzles and light storylines that are gradually revealed as the player progresses through the renovation process. Upkeep also emphasizes simplicity across all design aspects, including puzzle mechanics, user interface, and visual presentation. This approach allows for a greater range of accessibility between users while also engaging them in a simple and relaxing gameplay experience.
- Repository: [Upkeep](https://github.com/TJeffrey237/CS386Project)

# Verification #
Verification aims to ensure that you correctly developed the product. 

For this deliverable, show an example of a unit test that uses mock objects to isolate the class from the rest of the system. 

Test framework you used to develop your tests (e.g., JUnit, unittest, pytest, etc.)
Link to your GitHub folder where your automated unit tests are located.
An example of a test case that makes use of mock objects. Include in your answer a GitHub link to the class being tested and to the test.
A print screen showing the result of the unit tests execution. 

# Acceptance Test #
An acceptance test is a test that verifies the correct implementation of a feature from the user interface perspective. An acceptance test is a black box test (the system is tested without knowledge about its internal implementation). Provide the following information:

Test framework you used to develop your tests (e.g., Selenium, Katalon Studio, Espresso2, Cucumber, etc.)
Link to your GitHub folder where your automated acceptance tests are located.
An example of an acceptance test. Include in your answer a GitHub link to the test and an explanation about the tested feature.
A print screen/video showing the acceptance test execution. 


# Validation #
At the beginning of the semester, you talked to the clients/potential users to understand their needs. Now it is time to check if you are on the right track by conducting some user evaluation on the actual system. Include in this deliverable the following information:

Script: The script should have the tasks that you gave to the user, what data you collected, and the questions you asked. In particular, do not forget to add questions about the users’ general impressions. You can ask open questions (e.g., How would you describe the homepage of our app? How do you compare our system to the competitor X?) or closed questions (On a scale of 1 to 10, how would you rate the layout of our application? On the same scale, how likely would you use the system in its current state?). Take a look at the inception and requirements deliverables to help create the script. Design a script to check if you are achieving your initial goals and if the features are implemented in a satisfactory way. 

Results: Conduct the user evaluation with at least 3 users. Report the data that you collected.

Reflections: Reflect on what you observed. Some questions that you can explore: What features worked well? What can be changed? How is the learning curve of your system? Did the users perform the tasks as you expected? Did the users’ actions produce the results they expected? What did the users like the most? Is your value proposition accomplished?

## Script ##
### Introduction ###
Introduce product and briefly describe what user will be doing and what sorts of information will be collected throughout play session. Instruct user to also think-aloud throughout the session and emphasize the fact that all thoughts are welcome positive or negative.
- **Example**: "Hello! I appreciate your participation. Today, we're going to play through a game that's currently in development. During the session, I’ll ask you a few questions and observe your playthrough. There are no right or wrong answers, we’re just here to learn from your experience! If at any point you get stuck or confused, just know that it is completely normal and is helpful to us. Additionally, try to think aloud as you play as this helps to communicate your thoughts to us."
### Play Session & Observations ###
In this section, participants will be asked to progress through the entirely of the game in whatever manner they please. They will be asked to think-aloud throughout the duration of the play session. As observers, we are looking to answer the following questions:
- Are they speaking aloud?
- Are they havinbg any difficulties at any certain point?
- Are they progressing through the game in the intended way?
- Are there any unexpected actions or results from the users?
### Post-Play Session Interview ###
After users complete a full walkthrough of the game, they will then be asked a series of interview questions to better help us understand their opinions on different aspects of the game:

**General Impressions**
- What are your general impressions on the overall layout of the game?

**Art-Style**
- Do you find the art-style appealing? Why or why not?

**Puzzle Experience**
- How intuitive did each puzzle feel to you?
- Which puzzles did you struggle the most with?

**Core Idea**
- What are your thoughts on the overarching idea behind the game?

**Expansion Ideas**
- If you could add any puzzles to this game, what kinds would you add?

**Engagement & Future Use**
- How likely are you to continue using the system in its current form?
- If unlikely, what are some things you would change to make it more engaging?

**Best & Worst**
- What is your biggest issue with this product?
- What is your favorite aspect of this product?

**Comparison**
- How would you compare our game to other similar products, like *A Little to the Left*?

**Clarity of Goals**
- On a scale from 1-10, how clear was the goal of the game for you?
   
### Closing ###
For the final portion of the evaluation, we express our gratitude to the participants for helping us collect information and provide contact information in the event they have future thoughts to share with us.
- **Example**: "That’s everything! Thanks again for taking the time to share your feedback and it will be very valuable in helping us improve our product. If you have any other thoughts after today, feel free to reach us at my email: tsj78@nau.edu."

## Results ##
### Session 1 ###
**Playtester**: Madison Price<br/>
**Interviwer**: Tyler Jeffrey<br/>
**Observations**:
- ...

**Post-Session Interview**:
- ...

### Session 2 ###
**Playtester**: Lydia Wolford<br/>
**Interviwer**: Tyler Jeffrey<br/>
**Observations**:
- ...

**Post-Session Interview**:
- ...

### Session 3 ###
**Playtester**: blank<br/>
**Interviwer**: blank<br/>
**Observations**:
- ...

**Post-Session Interview**:
- ...
## Reflection ##
